menu_path=Preprocessing/additions
label=Lowercase, Tokenize, Stem, and Stopword Text
description=This algorithm normalizes the text in one or more columns.
in_data=prefuse.data.Table
out_data=prefuse.data.Table
service.pid=edu.iu.nwb.preprocessing.text.normalization.StandardNormalyzer
implementers=Apache Lucene project
integrators=Russell Duhon
documentation_url=http://wiki.slis.indiana.edu:8080/display/ALGDOC/Lowercase,+Tokenize,+Stem,+and+Stopword+Text
remoteable=true
